import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from dataset import EnergyDataset
from model import BiLSTMModel
import os

# âš™ï¸ Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
input_window = 168
output_window = 24
batch_size = 32
num_epochs = 7
learning_rate = 0.001
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ğŸ“¦ Ø¯ÛŒØªØ§Ø³Øª Ùˆ DataLoader
dataset = EnergyDataset("./DUQ_hourly.csv",input_window,output_window,split="train")
train_loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)


# ğŸ§  Ù…Ø¯Ù„
model =  BiLSTMModel(input_size=1,hidden_size=64,num_layers=2,output_window=output_window).to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)




# ğŸ“ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
checkpoint_dir = "checkpoints"
os.makedirs(checkpoint_dir,exist_ok=True)
model_path = os.path.join(checkpoint_dir,"bilstm_model.pth")



# ğŸ” Ø­Ù„Ù‚Ù‡ Ø¢Ù…ÙˆØ²Ø´

for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for x,y in train_loader:
         x = x.to(device)  # [B, T] â†’ [B, T, 1]
         y = y.to(device)
         optimizer.zero_grad()
         output = model(x)
         loss = criterion(output,y)
         loss.backward()
         optimizer.step()
         total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f}")



# ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„

torch.save(model.state_dict(),model_path)
print(f"âœ… Model saved to: {model_path}")